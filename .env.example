 OLLAMA_BASE_URL=http://localhost:11434 # the endpoint of the Ollama service, defaults to http://localhost:11434 if not set
OLLAMA_MODEL=llama3.2 # the name of the model to use, defaults to 'llama3.2' if not set

# Which search service to use, either 'duckduckgo', 'tavily', 'perplexity', Searxng
SEARCH_API='duckduckgo'
# For Searxng search, defaults to http://localhost:8888
SEARXNG_URL=

# Web Search API Keys (choose one or both)
TAVILY_API_KEY=tvly-xxxxx      # Get your key at https://tavily.com
PERPLEXITY_API_KEY=pplx-xxxxx  # Get your key at https://www.perplexity.ai

# LLM Configuration
LLM_PROVIDER=openai          # Options: ollama, lmstudio, openai
# LOCAL_LLM=qwen_qwq-32b         # Model name in LMStudio
# LMSTUDIO_BASE_URL=http://localhost:1234/v1  # LMStudio OpenAI-compatible API URL

# OpenAI Configuration
OPENAI_API_KEY=sk-your-api-key-here
OPENAI_MODEL=gpt-4-turbo

# LangChain Configuration
LANGCHAIN_API_KEY=lsv2_xxxx
LANGSMITH_API_KEY=lsv2_xxxx
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=langgraph_studio

MAX_WEB_RESEARCH_LOOPS=3
FETCH_FULL_PAGE=True